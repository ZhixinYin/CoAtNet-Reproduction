{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTZg7xSDMpiU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = \"/content/tiny-imagenet-200\"\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "images_dir = os.path.join(val_dir, \"images\")\n",
        "ann_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
        "\n",
        "# Read annotations\n",
        "with open(ann_file) as f:\n",
        "    annotations = [line.strip().split('\\t') for line in f]\n",
        "\n",
        "# Create class folders and move images\n",
        "for img, cls, *_ in annotations:\n",
        "    cls_dir = os.path.join(val_dir, cls)\n",
        "    os.makedirs(cls_dir, exist_ok=True)\n",
        "    shutil.move(\n",
        "        os.path.join(images_dir, img),\n",
        "        os.path.join(cls_dir, img)\n",
        "    )\n",
        "\n",
        "os.rmdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCCUJevDM5N2",
        "outputId": "70898af7-9444-4e2c-9182-ffaa6d3ca567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mklmSxIRM7DE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfla\n",
        "import tensorflow.keras.models as tfm\n",
        "import tensorflow.keras.optimizers as tfo\n",
        "import tensorflow.keras.losses as tflo\n",
        "import matplotlib.pyplot as plt\n",
        "from official.vision.ops import augment\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-zbJnAVM86u",
        "outputId": "efafd297-53f9-428b-f0bf-93b911d79fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100000 files belonging to 200 classes.\n",
            "Found 10000 files belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "with open(\"tiny-imagenet-200/wnids.txt\") as f:\n",
        "    wnids = [line.strip() for line in f]\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(256, 256),\n",
        "    batch_size=None,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/val\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plCQzq_kM--l"
      },
      "outputs": [],
      "source": [
        "def crop_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  image = tf.image.random_crop(image, (224, 224, 3))\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Qf71TTNBIO"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(crop_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfl8VQxfNC4x"
      },
      "outputs": [],
      "source": [
        "def normalise_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  mean = tf.constant([0.485, 0.456, 0.406])\n",
        "  std = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "  image = (image / 255.0 - mean) / std\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSQmNrzgNEnK"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfBJRPE9NGbG"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(128)\n",
        "combined_ds = train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l_n1DmVNH8W"
      },
      "outputs": [],
      "source": [
        "def mixup(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  images_lam = tf.reshape(lam, [-1, 1, 1, 1])\n",
        "  labels_lam = lam\n",
        "\n",
        "\n",
        "  images = images_lam * images + (1 - images_lam) * shuffled_images\n",
        "  labels = labels_lam * labels + (1 - labels_lam) * shuffled_labels\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mugDNzSwNJ3u"
      },
      "outputs": [],
      "source": [
        "mixup_ds = train_ds.map(mixup, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(mixup_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr1Q_jn2NLbm"
      },
      "outputs": [],
      "source": [
        "def cutmix(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  cut_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  cut_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(cut_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - cut_height // 2, tf.int32)\n",
        "  cut_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_x = cut_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(cut_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - cut_width // 2, tf.int32)\n",
        "  cut_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_y = cut_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(cut_centre_x, tf.int32) - cut_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(cut_centre_x, tf.int32) + cut_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(cut_centre_y, tf.int32) - cut_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(cut_centre_y, tf.int32) + cut_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32) + shuffled_images * tf.cast(mask, dtype=tf.float32)\n",
        "  labels = labels * (1.0 - lam) + shuffled_labels * lam\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KBgKf3CNNVP"
      },
      "outputs": [],
      "source": [
        "cutmix_ds = train_ds.map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(cutmix_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1KQGyikNPI1"
      },
      "outputs": [],
      "source": [
        "def erase(images, labels):\n",
        "  # images shape: [batch_size, h, w, c]\n",
        "  # labels shape: [batch_size, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = tf.random.uniform(shape=(batch_size, 1), minval=0.2, maxval=0.5, dtype=tf.float32)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  erase_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  erase_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(erase_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - erase_height // 2, tf.int32)\n",
        "  erase_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_x = erase_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(erase_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - erase_width // 2, tf.int32)\n",
        "  erase_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_y = erase_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(erase_centre_x, tf.int32) - erase_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(erase_centre_x, tf.int32) + erase_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(erase_centre_y, tf.int32) - erase_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(erase_centre_y, tf.int32) + erase_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjzOKZDZNQ0X"
      },
      "outputs": [],
      "source": [
        "erase_ds = train_ds.map(erase, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(erase_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lnpj-a_NTFT"
      },
      "outputs": [],
      "source": [
        "def label_smoothing(labels, epsilon=0.1):\n",
        "  num_class = tf.cast(tf.shape(labels)[1], tf.float32)\n",
        "  return labels * (1.0 - epsilon) + epsilon / num_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onlJFyc1NUgj"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.map(lambda images, labels: (images, label_smoothing(labels)), num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW32hMeiNWFo"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.shuffle(buffer_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exs0uK77NXlE"
      },
      "outputs": [],
      "source": [
        "class MBConv(tfla.Layer):\n",
        "  def __init__(self, dim, out_channels):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.conv1 = tfla.Conv2D(dim * 4, 1, strides=1, padding=\"same\", use_bias=False)\n",
        "    self.bn1 = tfla.BatchNormalization()\n",
        "    self.gelu1 = tfla.Activation(\"gelu\")\n",
        "    self.depthwise = tfla.DepthwiseConv2D(3, strides=1, padding=\"same\", use_bias=False)\n",
        "    self.globalaverage = tfla.GlobalAveragePooling2D()\n",
        "    self.dense1 = tfla.Dense(dim, activation=\"gelu\")\n",
        "    self.dense2 = tfla.Dense(dim * 4, activation=\"sigmoid\")\n",
        "    self.conv2 = tfla.Conv2D(out_channels, 1, strides=1, padding=\"same\", use_bias=False)\n",
        "    self.bn2 = tfla.BatchNormalization()\n",
        "    self.shortcut = tfla.Conv2D(out_channels, 1, strides=1, padding=\"same\", use_bias=False)\n",
        "\n",
        "  def call(self, x):\n",
        "    # x shape:[B, H, W, C]\n",
        "    shortcut = self.shortcut(x)\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.gelu1(x)\n",
        "    x = self.depthwise(x)\n",
        "\n",
        "    sne = self.globalaverage(x)\n",
        "    sne = self.dense1(sne)\n",
        "    sne = self.dense2(sne)\n",
        "    sne = tf.expand_dims(sne, axis=1)\n",
        "    sne = tf.expand_dims(sne, axis=1)\n",
        "\n",
        "    x = x * sne\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    # return shape:[B, H, W, out_channels]\n",
        "    return x + shortcut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4URrq8gRzir"
      },
      "outputs": [],
      "source": [
        "class self_attention(tfla.Layer):\n",
        "  def __init__(self, dim, window_size, num_heads):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.window_size = window_size\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dims = dim // num_heads\n",
        "    self.N = window_size * window_size\n",
        "    self.scale = tf.cast(self.head_dims, tf.float32) ** -0.5\n",
        "    self.toqkv = tfla.Dense(dim * 3, use_bias=False)\n",
        "    self.dense = tfla.Dense(dim)\n",
        "\n",
        "    self.num_rel_pos = (2 * window_size - 1) * (2 * window_size - 1)\n",
        "    self.rel_pos = self.add_weight(\n",
        "        shape=(self.num_rel_pos, num_heads),\n",
        "        initializer=tf.random_normal_initializer(stddev=0.02),\n",
        "        trainable=True\n",
        "    )\n",
        "\n",
        "    coords_h = tf.range(window_size)\n",
        "    coords_w = tf.range(window_size)\n",
        "    # coords shape:[2, window_size, window_size]\n",
        "    coords = tf.stack(tf.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "    # coords shape:[2, N]\n",
        "    coords = tf.reshape(coords, shape=(2, -1))\n",
        "    # rel_pos shape:[2, N, N]\n",
        "    rel_pos = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "    # rel_pos_h and rel_pos_w shape:[N, N]\n",
        "    rel_pos_h = rel_pos[0] + window_size - 1\n",
        "    rel_pos_w = rel_pos[1] + window_size - 1\n",
        "\n",
        "    # rel_index shape:[N, N]\n",
        "    self.rel_index = rel_pos_h * (2 * window_size - 1) + rel_pos_w\n",
        "\n",
        "  def call(self, x):\n",
        "    # x shape:[B, N, C]\n",
        "    # qkv shape:[B, N, 3 * C]\n",
        "    x = self.toqkv(x)\n",
        "\n",
        "    # x shape:[B, N, 3, num_heads, head_dims]\n",
        "    x = tf.reshape(x, shape=(-1, self.N, 3, self.num_heads, self.head_dims))\n",
        "\n",
        "    # x shape:[3, B, num_heads, N, head_dims]\n",
        "    x = tf.transpose(x, perm=(2, 0, 3, 1, 4))\n",
        "    # q, k, v shape:[B, num_heads, N, head_dims]\n",
        "    q, k, v = x[0], x[1], x[2]\n",
        "\n",
        "    # attn shape:[B, num_heads, N, N]\n",
        "    attn = tf.matmul(q, k, transpose_b=True)\n",
        "    attn = attn * self.scale\n",
        "\n",
        "    # rel_pos shape:[N, N, num_heads]\n",
        "    rel_pos = tf.gather(self.rel_pos, self.rel_index)\n",
        "    rel_pos = tf.transpose(rel_pos, perm=(2, 0, 1))\n",
        "    # rel_pos shape:[1, num_heads, N, N]\n",
        "    rel_pos = tf.reshape(rel_pos, shape=(1, self.num_heads, self.N, self.N))\n",
        "\n",
        "    attn = attn + rel_pos\n",
        "    attn = tf.nn.softmax(attn, axis=-1)\n",
        "    # attn shape:[B, num_heads, N, head_dims]\n",
        "    attn = tf.matmul(attn, v)\n",
        "\n",
        "    # attn shape:[B, N, num_heads, head_dims]\n",
        "    attn = tf.transpose(attn, perm=(0, 2, 1, 3))\n",
        "    attn = tf.reshape(attn, shape=(-1, self.N, self.dim))\n",
        "\n",
        "    # return shape:[B, N, C]\n",
        "    return attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX7LNImj7oPA",
        "outputId": "e3533593-ead1-4707-9e3f-775edf3047a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'self_attention', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'self_attention_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "inputs = tfla.Input(shape=(224, 224, 3))\n",
        "\n",
        "# x shape:[B, 112, 112, 64]\n",
        "x = tfla.Conv2D(64, 3, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
        "x = tfla.BatchNormalization()(x)\n",
        "x = tfla.Activation(\"gelu\")(x)\n",
        "\n",
        "x = MBConv(dim=64, out_channels=96)(x)\n",
        "# x shape:[B, 56, 56, 96]\n",
        "x = tfla.Conv2D(96, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "x = MBConv(dim=96, out_channels=192)(x)\n",
        "#x shape:[B, 28, 28, 192]\n",
        "x = tfla.Conv2D(192, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "x = tfla.Reshape((784, 192))(x)\n",
        "# x shape:[B, 784, 192]\n",
        "x = self_attention(dim=192, window_size=28, num_heads=12)(x)\n",
        "x = tfla.Reshape((28, 28, 192))(x)\n",
        "# x shape:[B, 14, 14, 192]\n",
        "x = tfla.Conv2D(384, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "x = tfla.Reshape((14 * 14, 384))(x)\n",
        "x = self_attention(dim=384, window_size=14, num_heads=12)(x)\n",
        "x = tfla.Reshape((14, 14, 384))(x)\n",
        "# x shape:[B, 7, 7, 384]\n",
        "x = tfla.Conv2D(384, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "x = tfla.GlobalAveragePooling2D()(x)\n",
        "outputs = tfla.Dense(200, activation=\"softmax\")(x)\n",
        "\n",
        "model = tfm.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "i3OOy87--p6m",
        "outputId": "4464583c-6bc0-48f0-e052-97d5a7f61290"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,904</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">208,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">331,776</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">self_attention</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">146,892</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">663,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">451,116</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">self_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">77,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv (\u001b[38;5;33mMBConv\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m83,904\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m82,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_1 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m208,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m331,776\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention (\u001b[38;5;33mself_attention\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │       \u001b[38;5;34m146,892\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m663,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │       \u001b[38;5;34m451,116\u001b[0m │\n",
              "│ (\u001b[38;5;33mself_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │     \u001b[38;5;34m1,327,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m77,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,375,264</span> (12.88 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,375,264\u001b[0m (12.88 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,373,280</span> (12.87 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,373,280\u001b[0m (12.87 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mED8t6feDzmp"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = 3128\n",
        "epochs = 80\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=5e-4,\n",
        "    decay_steps=total_steps,\n",
        "    alpha=1e-2\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=5e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMiiWz0YEHzQ",
        "outputId": "9f1d19fb-2d86-4563-924c-7038f6fee651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 180ms/step - accuracy: 0.0982 - loss: 4.5823\n",
            "Epoch 2/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.2442 - loss: 3.7919\n",
            "Epoch 3/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.3115 - loss: 3.5013\n",
            "Epoch 4/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.3585 - loss: 3.3166\n",
            "Epoch 5/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.3908 - loss: 3.1849\n",
            "Epoch 6/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.4199 - loss: 3.0748\n",
            "Epoch 7/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.4451 - loss: 2.9805\n",
            "Epoch 8/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 161ms/step - accuracy: 0.4663 - loss: 2.9002\n",
            "Epoch 9/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.4865 - loss: 2.8270\n",
            "Epoch 10/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.5044 - loss: 2.7611\n",
            "Epoch 11/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.5227 - loss: 2.6940\n",
            "Epoch 12/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.5405 - loss: 2.6357\n",
            "Epoch 13/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.5579 - loss: 2.5780\n",
            "Epoch 14/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.5741 - loss: 2.5227\n",
            "Epoch 15/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.5896 - loss: 2.4689\n",
            "Epoch 16/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.6049 - loss: 2.4211\n",
            "Epoch 17/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.6208 - loss: 2.3687\n",
            "Epoch 18/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.6370 - loss: 2.3196\n",
            "Epoch 19/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.6543 - loss: 2.2675\n",
            "Epoch 20/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.6717 - loss: 2.2138\n",
            "Epoch 21/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.6859 - loss: 2.1701\n",
            "Epoch 22/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.7029 - loss: 2.1246\n",
            "Epoch 23/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.7176 - loss: 2.0822\n",
            "Epoch 24/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.7352 - loss: 2.0364\n",
            "Epoch 25/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.7498 - loss: 1.9966\n",
            "Epoch 26/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.7620 - loss: 1.9615\n",
            "Epoch 27/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.7737 - loss: 1.9293\n",
            "Epoch 28/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.7878 - loss: 1.8939\n",
            "Epoch 29/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8001 - loss: 1.8660\n",
            "Epoch 30/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8139 - loss: 1.8282\n",
            "Epoch 31/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 161ms/step - accuracy: 0.8235 - loss: 1.8036\n",
            "Epoch 32/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8325 - loss: 1.7816\n",
            "Epoch 33/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.8428 - loss: 1.7531\n",
            "Epoch 34/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8532 - loss: 1.7289\n",
            "Epoch 35/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8604 - loss: 1.7107\n",
            "Epoch 36/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.8691 - loss: 1.6856\n",
            "Epoch 37/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8759 - loss: 1.6668\n",
            "Epoch 38/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8818 - loss: 1.6480\n",
            "Epoch 39/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.8872 - loss: 1.6335\n",
            "Epoch 40/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.8938 - loss: 1.6141\n",
            "Epoch 41/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.8999 - loss: 1.5958\n",
            "Epoch 42/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9037 - loss: 1.5839\n",
            "Epoch 43/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9092 - loss: 1.5679\n",
            "Epoch 44/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9133 - loss: 1.5533\n",
            "Epoch 45/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.9172 - loss: 1.5398\n",
            "Epoch 46/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9213 - loss: 1.5263\n",
            "Epoch 47/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9253 - loss: 1.5140\n",
            "Epoch 48/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9267 - loss: 1.5074\n",
            "Epoch 49/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9298 - loss: 1.4935\n",
            "Epoch 50/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9332 - loss: 1.4802\n",
            "Epoch 51/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9362 - loss: 1.4696\n",
            "Epoch 52/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.9376 - loss: 1.4631\n",
            "Epoch 53/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9399 - loss: 1.4508\n",
            "Epoch 54/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9413 - loss: 1.4450\n",
            "Epoch 55/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9429 - loss: 1.4353\n",
            "Epoch 56/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.9446 - loss: 1.4281\n",
            "Epoch 57/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9470 - loss: 1.4179\n",
            "Epoch 58/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9478 - loss: 1.4098\n",
            "Epoch 59/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9487 - loss: 1.4040\n",
            "Epoch 60/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9504 - loss: 1.3966\n",
            "Epoch 61/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9513 - loss: 1.3899\n",
            "Epoch 62/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9521 - loss: 1.3846\n",
            "Epoch 63/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.9534 - loss: 1.3780\n",
            "Epoch 64/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 161ms/step - accuracy: 0.9541 - loss: 1.3715\n",
            "Epoch 65/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9542 - loss: 1.3673\n",
            "Epoch 66/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9552 - loss: 1.3634\n",
            "Epoch 67/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9560 - loss: 1.3579\n",
            "Epoch 68/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9563 - loss: 1.3554\n",
            "Epoch 69/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9567 - loss: 1.3520\n",
            "Epoch 70/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9573 - loss: 1.3486\n",
            "Epoch 71/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9579 - loss: 1.3444\n",
            "Epoch 72/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9582 - loss: 1.3420\n",
            "Epoch 73/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9580 - loss: 1.3402\n",
            "Epoch 74/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9582 - loss: 1.3387\n",
            "Epoch 75/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9587 - loss: 1.3361\n",
            "Epoch 76/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 161ms/step - accuracy: 0.9594 - loss: 1.3327\n",
            "Epoch 77/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9591 - loss: 1.3318\n",
            "Epoch 78/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9592 - loss: 1.3326\n",
            "Epoch 79/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 161ms/step - accuracy: 0.9591 - loss: 1.3312\n",
            "Epoch 80/80\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 161ms/step - accuracy: 0.9589 - loss: 1.3317\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    combined_ds,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "530iyIA8ELTk",
        "outputId": "bb6b5c06-ac64-424f-c709-f8205e1a135b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 217ms/step - accuracy: 0.4480 - loss: 2.6958\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.679743528366089, 0.44670000672340393]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ADt1una8EMjW"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}